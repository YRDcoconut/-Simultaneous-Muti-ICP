{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: CORE SECTION (ICP Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found resources\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# Path to Resources\n",
    "RES_PATH = './bunny/data_rough_aligned'\n",
    "COR_PATH = './bunny/correspondences'\n",
    "\n",
    "# Checking if the path is found locally\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print( 'cannot find mesh resources dir, please update RES_PATH')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('found resources')\n",
    "\n",
    "# Loading libraries for basic geometry processing\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration with multiple scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given multiple scans M1,M2,...M5 align all of them to a common global coordinate frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (40091, 3)\n",
      "M3 shape of Vertices: (30373, 3)\n",
      "M4 shape of Vertices: (40247, 3)\n",
      "M5 shape of Vertices: (31697, 3)\n",
      "[<trimesh.PointCloud(vertices.shape=(40256, 3), name=`bun000.ply`)>, <trimesh.Trimesh(vertices.shape=(40091, 3), faces.shape=(79057, 3), name=`bun045.ply`)>, <trimesh.Trimesh(vertices.shape=(30373, 3), faces.shape=(59629, 3), name=`bun090.ply`)>, <trimesh.Trimesh(vertices.shape=(40247, 3), faces.shape=(79284, 3), name=`bun180.ply`)>, <trimesh.Trimesh(vertices.shape=(31697, 3), faces.shape=(62335, 3), name=`bun270.ply`)>]\n"
     ]
    }
   ],
   "source": [
    "# Load point cloud models M1 ~ M5\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun090.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)\n",
    "\n",
    "mesh_fp3 = os.path.join(RES_PATH,'bun180.ply')\n",
    "assert os.path.exists(mesh_fp3), 'Cannot find:' + mesh_fp3\n",
    "M3 = trimesh.load(mesh_fp3)\n",
    "print('M3 shape of Vertices:', M3.vertices.shape)\n",
    "\n",
    "mesh_fp4 = os.path.join(RES_PATH,'bun270.ply')\n",
    "assert os.path.exists(mesh_fp4), 'Cannot find:' + mesh_fp4\n",
    "M4 = trimesh.load(mesh_fp4)\n",
    "print('M4 shape of Vertices:', M4.vertices.shape)\n",
    "\n",
    "mesh_fp5 = os.path.join(RES_PATH,'top2.ply')\n",
    "assert os.path.exists(mesh_fp5), 'Cannot find:' + mesh_fp5\n",
    "M5 = trimesh.load(mesh_fp5)\n",
    "print('M5 shape of Vertices:', M5.vertices.shape)\n",
    "\n",
    "mesh_fp6 = os.path.join(RES_PATH,'chin.ply')\n",
    "assert os.path.exists(mesh_fp6), 'Cannot find:' + mesh_fp6\n",
    "M6 = trimesh.load(mesh_fp6)\n",
    "print('M6 shape of Vertices:', M6.vertices.shape)\n",
    "\n",
    "# Create a list to store models to be registered\n",
    "models = [M1, M2, M3, M4, M5, M6]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans(scans, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as the previous one\n",
    "        reference_scan = aligned_scans[i-1].vertices.copy()\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge at iteration 32\n",
      "Processing model M3...\n",
      "Converge at iteration 70\n",
      "Processing model M4...\n",
      "Converge at iteration 99\n",
      "Processing model M5...\n",
      "Converge at iteration 60\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results/multiple_scans/method1/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans_2(scans, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as all the other scans\n",
    "        other_scans = scans[:i] + scans[i+1:]\n",
    "        reference_scan = np.concatenate([s.vertices.copy() for s in other_scans])\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n",
      "Converge at iteration 64\n",
      "Processing model M3...\n",
      "Converge at iteration 55\n",
      "Processing model M4...\n",
      "Converge at iteration 54\n",
      "Processing model M5...\n",
      "Converge at iteration 39\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans_2(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results/multiple_scans/method2/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous Multiview Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found resources\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# Path to Resources\n",
    "RES_PATH = './bunny/data_rough_aligned'\n",
    "COR_PATH = './bunny/correspondences'\n",
    "\n",
    "# Checking if the path is found locally\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print( 'cannot find mesh resources dir, please update RES_PATH')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('found resources')\n",
    "\n",
    "# Loading libraries for basic geometry processing\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 6  # (M) There are 6 views in the example (V1 to V6)\n",
    "num_correspondences = 12  # (P) There are 12 correspondence sets (S1 to S12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (30373, 3)\n",
      "M3 shape of Vertices: (40247, 3)\n",
      "M4 shape of Vertices: (31697, 3)\n",
      "M5 shape of Vertices: (38297, 3)\n",
      "M6 shape of Vertices: (37737, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load multi-views point cloud models M1 ~ M6\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun090.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)\n",
    "\n",
    "mesh_fp3 = os.path.join(RES_PATH,'bun180.ply')\n",
    "assert os.path.exists(mesh_fp3), 'Cannot find:' + mesh_fp3\n",
    "M3 = trimesh.load(mesh_fp3)\n",
    "print('M3 shape of Vertices:', M3.vertices.shape)\n",
    "\n",
    "mesh_fp4 = os.path.join(RES_PATH,'bun270.ply')\n",
    "assert os.path.exists(mesh_fp4), 'Cannot find:' + mesh_fp4\n",
    "M4 = trimesh.load(mesh_fp4)\n",
    "print('M4 shape of Vertices:', M4.vertices.shape)\n",
    "\n",
    "mesh_fp5 = os.path.join(RES_PATH,'top2.ply')\n",
    "assert os.path.exists(mesh_fp5), 'Cannot find:' + mesh_fp5\n",
    "M5 = trimesh.load(mesh_fp5)\n",
    "print('M5 shape of Vertices:', M5.vertices.shape)\n",
    "\n",
    "mesh_fp6 = os.path.join(RES_PATH,'chin.ply')\n",
    "assert os.path.exists(mesh_fp6), 'Cannot find:' + mesh_fp6\n",
    "M6 = trimesh.load(mesh_fp6)\n",
    "print('M6 shape of Vertices:', M6.vertices.shape)\n",
    "\n",
    "# Create a list to store models to be registered\n",
    "models = [M1.vertices.copy(), M2.vertices.copy(), M3.vertices.copy(), M4.vertices.copy(), M5.vertices.copy(), M6.vertices.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bun000_CPSet000_090.ply shape of Vertices: (30379, 3)\n",
      "bun090_CPSet000_090.ply shape of Vertices: (40256, 3)\n",
      "bun090_CPSet090_180.ply shape of Vertices: (40251, 3)\n",
      "bun180_CPSet090_180.ply shape of Vertices: (30379, 3)\n",
      "bun180_CPSet180_270.ply shape of Vertices: (31701, 3)\n",
      "bun270_CPSet180_270.ply shape of Vertices: (40251, 3)\n",
      "bun270_CPSet000_270.ply shape of Vertices: (40256, 3)\n",
      "bun000_CPSet000_270.ply shape of Vertices: (31701, 3)\n",
      "bun000_CPSet000_top.ply shape of Vertices: (38298, 3)\n",
      "top_CPSet000_top.ply shape of Vertices: (40256, 3)\n",
      "bun090_CPSet090_top.ply shape of Vertices: (38298, 3)\n",
      "top_CPSet090_top.ply shape of Vertices: (30379, 3)\n",
      "bun180_CPSet180_top.ply shape of Vertices: (38298, 3)\n",
      "top_CPSet180_top.ply shape of Vertices: (40251, 3)\n",
      "bun270_CPSet270_top.ply shape of Vertices: (38298, 3)\n",
      "top_CPSet270_top.ply shape of Vertices: (31701, 3)\n",
      "bun000_CPSet000_chin.ply shape of Vertices: (37738, 3)\n",
      "chin_CPSet000_chin.ply shape of Vertices: (40256, 3)\n",
      "bun090_CPSet090_chin.ply shape of Vertices: (37738, 3)\n",
      "chin_CPSet090_chin.ply shape of Vertices: (30379, 3)\n",
      "bun180_CPSet180_chin.ply shape of Vertices: (37738, 3)\n",
      "chin_CPSet180_chin.ply shape of Vertices: (40251, 3)\n",
      "bun270_CPSet270_chin.ply shape of Vertices: (37738, 3)\n",
      "chin_CPSet270_chin.ply shape of Vertices: (31701, 3)\n",
      "Total number of vertex arrays in X: 12\n",
      "Total number of vertex arrays in Y: 12\n"
     ]
    }
   ],
   "source": [
    "# Load multi-views point cloud models C1_i ~ C12_i\n",
    "\n",
    "# Create a list to store correspondences\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "file_names = [\n",
    "    'bun000_CPSet000_090.ply',\n",
    "    'bun090_CPSet000_090.ply',\n",
    "    'bun090_CPSet090_180.ply',\n",
    "    'bun180_CPSet090_180.ply',\n",
    "    'bun180_CPSet180_270.ply',\n",
    "    'bun270_CPSet180_270.ply',\n",
    "    'bun270_CPSet000_270.ply',\n",
    "    'bun000_CPSet000_270.ply',\n",
    "    'bun000_CPSet000_top.ply',\n",
    "    'top_CPSet000_top.ply',\n",
    "    'bun090_CPSet090_top.ply',\n",
    "    'top_CPSet090_top.ply',\n",
    "    'bun180_CPSet180_top.ply',\n",
    "    'top_CPSet180_top.ply',\n",
    "    'bun270_CPSet270_top.ply',\n",
    "    'top_CPSet270_top.ply',\n",
    "    'bun000_CPSet000_chin.ply',\n",
    "    'chin_CPSet000_chin.ply',\n",
    "    'bun090_CPSet090_chin.ply',\n",
    "    'chin_CPSet090_chin.ply',\n",
    "    'bun180_CPSet180_chin.ply',\n",
    "    'chin_CPSet180_chin.ply',\n",
    "    'bun270_CPSet270_chin.ply',\n",
    "    'chin_CPSet270_chin.ply'\n",
    "]\n",
    "\n",
    "for i, filename in enumerate(file_names):\n",
    "    # 构造PLY文件的完整路径\n",
    "    cor_fp = os.path.join(COR_PATH, filename)\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    assert os.path.exists(cor_fp), 'Cannot find:' + cor_fp\n",
    "    \n",
    "    # 使用trimesh库加载PLY文件\n",
    "    cor_mesh = trimesh.load(cor_fp)\n",
    "\n",
    "    # 打印顶点数组的形状信息\n",
    "    print(filename, 'shape of Vertices:', cor_mesh.vertices.shape)\n",
    "    \n",
    "    # 根据文件顺序将顶点数组分别存储在X和Y列表中\n",
    "    if i % 2 == 0:  # 当X和Y长度相等时，将顶点数组存储在X列表中\n",
    "        X.append(cor_mesh.vertices.copy())\n",
    "    else:  # 当X和Y长度不相等时，将顶点数组存储在Y列表中\n",
    "        Y.append(cor_mesh.vertices.copy())\n",
    "\n",
    "# 打印X和Y列表中的顶点数组数量\n",
    "print(\"Total number of vertex arrays in X:\", len(X))\n",
    "print(\"Total number of vertex arrays in Y:\", len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the nearest neighbors between the corresponding scans\n",
    "for mu in range(num_correspondences):\n",
    "    tree = KDTree(Y[mu])\n",
    "    _, indices = tree.query(X[mu])\n",
    "\n",
    "    # Extract nearest points as the correspondences\n",
    "    Y[mu] = Y[mu][indices].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights all initialized to 1 for now\n",
    "weights = [np.ones(len(X[mu])) for mu in range(num_correspondences)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the View–Correspondence Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the View–Correspondence Mapping Table, construct the Cα and Cβ matrices.\n",
    "# These are \"view selection matrices\" that map correspondence sets to their respective views.\n",
    "\n",
    "# Define the mappings as provided in the table\n",
    "alpha_mapping = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]\n",
    "beta_mapping = [2, 3, 4, 1, 5, 5, 5, 5, 6, 6, 6, 6]\n",
    "\n",
    "# Initialize the selection matrices with zeros\n",
    "C_alpha = np.zeros((3 * num_views, 3 * num_correspondences))\n",
    "C_beta = np.zeros((3 * num_views, 3 * num_correspondences))\n",
    "\n",
    "# Fill in the selection matrices based on the mappings\n",
    "for mu in range(num_correspondences):\n",
    "    view_alpha = alpha_mapping[mu] - 1  # Adjust for zero-based indexing\n",
    "    view_beta = beta_mapping[mu] - 1  # Adjust for zero-based indexing\n",
    "\n",
    "    # Each correspondence set affects 3 rows and 3 columns, for x, y, z components\n",
    "    C_alpha[3*view_alpha:3*(view_alpha+1), 3*mu:3*(mu+1)] = np.eye(3)\n",
    "    C_beta[3*view_beta:3*(view_beta+1), 3*mu:3*(mu+1)] = np.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Q Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q(X, Y, weights):\n",
    "    ## Compute Q_R\n",
    "    # Initialize the H matrices as zero matrices of the appropriate size\n",
    "    Hxx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hyy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hxy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hyx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "\n",
    "    # Calculate the H matrices\n",
    "    for mu in range(num_correspondences):\n",
    "        # Weight each point's contribution to the outer product\n",
    "        weighted_X = X[mu] * weights[mu][:, np.newaxis]\n",
    "        weighted_Y = Y[mu] * weights[mu][:, np.newaxis]\n",
    "\n",
    "        Hxx_mu = weighted_X.T @ X[mu]\n",
    "        Hyy_mu = weighted_Y.T @ Y[mu]\n",
    "        Hxy_mu = weighted_X.T @ Y[mu]\n",
    "        Hyx_mu = Hxy_mu.T  # Hyx is the transpose of Hxy\n",
    "\n",
    "        # Place the computed matrices in their appropriate blocks in the H matrices\n",
    "        Hxx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hxx_mu\n",
    "        Hyy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hyy_mu\n",
    "        Hxy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hxy_mu\n",
    "        Hyx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hyx_mu\n",
    "\n",
    "    # Using the computed matrices to calculate Q_R\n",
    "    Q_R = C_alpha @ Hxx @ C_alpha.T + C_beta @ Hyy @ C_beta.T - C_alpha @ Hxy @ C_beta.T - C_beta @ Hyx @ C_alpha.T\n",
    "\n",
    "    ## Compute Q_R_T\n",
    "    # Step 1: Compute W_mu as the sum of weights for each correspondence\n",
    "    W_mu = np.array([np.sum(weights[mu]) for mu in range(num_correspondences)])\n",
    "\n",
    "    # Step 2: Create the W matrix\n",
    "    W = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    for mu in range(num_correspondences):\n",
    "        W[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.eye(3) * W_mu[mu]\n",
    "\n",
    "    # Step 3: Compute the matrix Gamma\n",
    "    N = np.eye(C_alpha.shape[1])  # ? unkown definition, set to identity for now\n",
    "    Gamma_matrix = W @ (C_alpha - C_beta).T @ np.linalg.pinv((C_alpha - C_beta) @ N @ (C_alpha - C_beta).T) @ (C_alpha - C_beta) @ W\n",
    "    # Extract gamma_coefficients from Gamma's diagonal blocks\n",
    "    gamma_coefficients = np.array([Gamma_matrix[3*mu, 3*mu] for mu in range(num_correspondences)])\n",
    "\n",
    "    # Step 4: Compute the weighted centroids for each correspondence set\n",
    "    weighted_centroids_x = [np.average(X[mu], weights=weights[mu], axis=0) for mu in range(num_correspondences)]\n",
    "    weighted_centroids_y = [np.average(Y[mu], weights=weights[mu], axis=0) for mu in range(num_correspondences)]\n",
    "\n",
    "    # Step 5: Compute the G matrices\n",
    "    Gxx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gyy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gxy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gyx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "\n",
    "    for mu in range(num_correspondences):\n",
    "        Gxx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_x[mu], weighted_centroids_x[mu]) * gamma_coefficients[mu]\n",
    "        Gyy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_y[mu], weighted_centroids_y[mu]) * gamma_coefficients[mu]\n",
    "        Gxy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_x[mu], weighted_centroids_y[mu]) * gamma_coefficients[mu]\n",
    "        Gyx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_y[mu], weighted_centroids_x[mu]) * gamma_coefficients[mu]\n",
    "\n",
    "    # Now use the G matrices and the view selection matrices to compute Q_R_T\n",
    "    Q_R_T = -C_alpha @ Gxx @ C_alpha.T + C_alpha @ Gxy @ C_beta.T + C_beta @ Gyx @ C_alpha.T - C_beta @ Gyy @ C_beta.T\n",
    "\n",
    "    # Compute Q matrix\n",
    "    Q = Q_R + Q_R_T\n",
    "\n",
    "    return Q, weighted_centroids_x, weighted_centroids_y, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative algorithm to solve for R and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_and_T(R, T, Q, weighted_centroids_x, weighted_centroids_y, W):\n",
    "    ## Solve for R\n",
    "    # Iterate over each view to optimize its rotation matrix\n",
    "    for j in range(num_views):\n",
    "        # Partition R into R_L, R_j, and R_U\n",
    "        R_L = R[:, :3*j]\n",
    "        R_j = R[:, 3*j:3*(j+1)]\n",
    "        R_U = R[:, 3*(j+1):]\n",
    "\n",
    "        # Partition Q into corresponding blocks\n",
    "        Q_jL = Q[3*j:3*(j+1), :3*j]\n",
    "        Q_jU = Q[3*j:3*(j+1), 3*(j+1):]\n",
    "\n",
    "        # Construct the S_j matrix for the j-th rotation\n",
    "        S_j = Q_jL @ R_L.T + Q_jU @ R_U.T\n",
    "\n",
    "        # Perform SVD of -S_j\n",
    "        U, _, Vt = np.linalg.svd(-S_j)\n",
    "\n",
    "        # Calculate the optimal R_j and update the corresponding block in R\n",
    "        R[:, 3*j:3*(j+1)] = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "    ## Solve for T\n",
    "    # Initialize Z as an empty list to collect the blocks\n",
    "    Z_blocks = []\n",
    "\n",
    "    # Construct Z by concatenating the relative displacements of the rotated centroids\n",
    "    for mu in range(num_correspondences):\n",
    "        rotated_centroid_x = R @ C_alpha[:, 3*mu:3*(mu+1)] @ weighted_centroids_x[mu]\n",
    "        rotated_centroid_y = R @ C_beta[:, 3*mu:3*(mu+1)] @ weighted_centroids_y[mu]\n",
    "        Z_block = rotated_centroid_x - rotated_centroid_y\n",
    "        Z_blocks.append(Z_block)\n",
    "\n",
    "    Z = np.concatenate(Z_blocks, axis=0)  # Combine the blocks vertically\n",
    "\n",
    "    # Construct matrices A and B\n",
    "    A = (C_alpha - C_beta) @ W @ (C_alpha - C_beta).T\n",
    "    B = (C_alpha - C_beta) @ W @ Z\n",
    "\n",
    "    # Solve for T_min using the pseudo-inverse of A\n",
    "    T_min = -np.linalg.pinv(A) @ B\n",
    "\n",
    "    T = T_min.reshape((3*num_views, 1))\n",
    "\n",
    "    return R, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simultaneous registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simultaneous_multiscans_registration(scans, X, Y, weights, max_iterations=100, tolerance=1e-6):\n",
    "    R = np.hstack([np.eye(3)] * num_views)\n",
    "    T = np.zeros((3*num_views, 1))\n",
    "\n",
    "    for iteration in range(1, max_iterations+1):\n",
    "        Q, weighted_centroids_x, weighted_centroids_y, W = compute_Q(X, Y, weights)\n",
    "        R, T = compute_R_and_T(R, T, Q, weighted_centroids_x, weighted_centroids_y, W)\n",
    "\n",
    "        # Update each model\n",
    "        for j in range(num_views):\n",
    "            # Extract the rotation matrix R_j for view j\n",
    "            R_j = R[:, 3*j:3*(j+1)]\n",
    "            \n",
    "            # Extract the translation vector T_j for view j\n",
    "            T_j = T[3*j:3*(j+1)]\n",
    "\n",
    "            scans[j] = (R_j @ models[j].T + T_j).T\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'Maximum iteration reached.')\n",
    "\n",
    "    return scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Maximum iteration reached.\n"
     ]
    }
   ],
   "source": [
    "models = simultaneous_multiscans_registration(models, X, Y, weights)\n",
    "\n",
    "for i, model_vertices in enumerate(models):\n",
    "    directory = './results/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    model = trimesh.points.PointCloud(model_vertices)\n",
    "    model.export(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
