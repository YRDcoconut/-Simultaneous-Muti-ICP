{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found resources\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# Path to Resources\n",
    "RES_PATH = './bunny/data_rough_aligned'\n",
    "COR_PATH = './bunny/correspondences'\n",
    "\n",
    "# Checking if the path is found locally\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print( 'cannot find mesh resources dir, please update RES_PATH')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('found resources')\n",
    "\n",
    "# Loading libraries for basic geometry processing\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration with multiple scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given multiple scans M1,M2,...M6 align all of them to a common global coordinate frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (30373, 3)\n",
      "M3 shape of Vertices: (40247, 3)\n",
      "M4 shape of Vertices: (31697, 3)\n",
      "M5 shape of Vertices: (38297, 3)\n",
      "M6 shape of Vertices: (37737, 3)\n",
      "[<trimesh.PointCloud(vertices.shape=(40256, 3), name=`bun000.ply`)>, <trimesh.Trimesh(vertices.shape=(30373, 3), faces.shape=(59629, 3), name=`bun090.ply`)>, <trimesh.Trimesh(vertices.shape=(40247, 3), faces.shape=(79284, 3), name=`bun180.ply`)>, <trimesh.Trimesh(vertices.shape=(31697, 3), faces.shape=(62335, 3), name=`bun270.ply`)>, <trimesh.Trimesh(vertices.shape=(38297, 3), faces.shape=(75530, 3), name=`top2.ply`)>, <trimesh.Trimesh(vertices.shape=(37737, 3), faces.shape=(74369, 3), name=`chin.ply`)>]\n"
     ]
    }
   ],
   "source": [
    "# Load point cloud models M1 ~ M6\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun090.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)\n",
    "\n",
    "mesh_fp3 = os.path.join(RES_PATH,'bun180.ply')\n",
    "assert os.path.exists(mesh_fp3), 'Cannot find:' + mesh_fp3\n",
    "M3 = trimesh.load(mesh_fp3)\n",
    "print('M3 shape of Vertices:', M3.vertices.shape)\n",
    "\n",
    "mesh_fp4 = os.path.join(RES_PATH,'bun270.ply')\n",
    "assert os.path.exists(mesh_fp4), 'Cannot find:' + mesh_fp4\n",
    "M4 = trimesh.load(mesh_fp4)\n",
    "print('M4 shape of Vertices:', M4.vertices.shape)\n",
    "\n",
    "mesh_fp5 = os.path.join(RES_PATH,'top2.ply')\n",
    "assert os.path.exists(mesh_fp5), 'Cannot find:' + mesh_fp5\n",
    "M5 = trimesh.load(mesh_fp5)\n",
    "print('M5 shape of Vertices:', M5.vertices.shape)\n",
    "\n",
    "mesh_fp6 = os.path.join(RES_PATH,'chin.ply')\n",
    "assert os.path.exists(mesh_fp6), 'Cannot find:' + mesh_fp6\n",
    "M6 = trimesh.load(mesh_fp6)\n",
    "print('M6 shape of Vertices:', M6.vertices.shape)\n",
    "\n",
    "# Create a list to store models to be registered\n",
    "models = [M1, M2, M3, M4, M5, M6]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans(scans, max_iterations=11, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as the previous one\n",
    "        reference_scan = aligned_scans[i-1].vertices.copy()\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 iterations complete.\n",
      "Processing model M3...\n",
      "11 iterations complete.\n",
      "Processing model M4...\n",
      "11 iterations complete.\n",
      "Processing model M5...\n",
      "11 iterations complete.\n",
      "Processing model M6...\n",
      "11 iterations complete.\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results/cw/method1/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_multiple_scans_2(scans, max_iterations=11, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Align multiple scans to a common global coordinate frame.\n",
    "\n",
    "    Args:\n",
    "    - scans: a list of numpy arrays representing the vertices of each scan (shape: [N_scan, Nx3])\n",
    "    - max_iterations: maximum number of iterations for ICP algorithm\n",
    "    - tolerance: tolerance for convergence\n",
    "\n",
    "    Returns:\n",
    "    - aligned_scans: a list of aligned scans (as trimesh.pointcloud.PointCloud objects)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list to store aligned scans\n",
    "    aligned_scans = []\n",
    "    aligned_scans.append(scans[0])\n",
    "\n",
    "    for i, scan in enumerate(scans[1:], start=1):\n",
    "        print(f'Processing model M{i+1}...')\n",
    "        # Copy the vertices to avoid modifying the original data\n",
    "        scan_vertices = scan.vertices.copy()\n",
    "\n",
    "        # Set reference scan as all the other scans\n",
    "        other_scans = scans[:i] + scans[i+1:]\n",
    "        reference_scan = np.concatenate([s.vertices.copy() for s in other_scans])\n",
    "\n",
    "        # Initialize rotation matrix R and translation vector t\n",
    "        R = np.eye(3)\n",
    "        t = np.zeros((3, 1))\n",
    "\n",
    "        # Perform ICP to align the current scan to the reference scan\n",
    "        for iteration in range(1, max_iterations+1):\n",
    "            # Find the nearest neighbors between the current scan and the reference scan\n",
    "            tree = KDTree(reference_scan)\n",
    "            _, indices = tree.query(scan_vertices)\n",
    "\n",
    "            # Extract corresponding points from the reference scan and the current scan\n",
    "            P = reference_scan[indices].squeeze()\n",
    "            Q = scan_vertices\n",
    "\n",
    "            # Compute the centroid of the matched points\n",
    "            centroid_P = np.mean(P, axis=0, keepdims=True)  #(1, 3)\n",
    "            centroid_Q = np.mean(Q, axis=0, keepdims=True)  #(1, 3)\n",
    "\n",
    "            # Compute the cross-covariance matrix\n",
    "            A = (Q - centroid_Q).T @ (P - centroid_P)   #(3, n) x (n, 3)\n",
    "\n",
    "            # Use Singular Value Decomposition (SVD) to compute the optimal rotation matrix R\n",
    "            U, _, Vt = np.linalg.svd(A)\n",
    "            R = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "            # Compute the optimal translation vector t\n",
    "            t = centroid_P.T - R @ centroid_Q.T\n",
    "\n",
    "            # Apply transformation to the current scan for the next iteration\n",
    "            scan_vertices = (R @ scan_vertices.T + t).T\n",
    "\n",
    "            # Check convergence\n",
    "            if np.linalg.norm(t) < tolerance:\n",
    "                print('Converge at iteration', iteration)\n",
    "                break\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'iterations complete.')\n",
    "\n",
    "        # Store the aligned scan\n",
    "        aligned_scan = trimesh.points.PointCloud(scan_vertices)\n",
    "        aligned_scans.append(aligned_scan)\n",
    "\n",
    "    return aligned_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model M2...\n",
      "11 iterations complete.\n",
      "Processing model M3...\n",
      "11 iterations complete.\n",
      "Processing model M4...\n",
      "11 iterations complete.\n",
      "Processing model M5...\n",
      "11 iterations complete.\n",
      "Processing model M6...\n",
      "11 iterations complete.\n"
     ]
    }
   ],
   "source": [
    "aligned_scans = align_multiple_scans_2(models)\n",
    "\n",
    "for i, aligned_scan in enumerate(aligned_scans):\n",
    "    directory = './results/cw/method2/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    aligned_scan.export(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous Multiview Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found resources\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "# Path to Resources\n",
    "RES_PATH = './bunny/data_rough_aligned'\n",
    "COR_PATH = './bunny/correspondences'\n",
    "\n",
    "# Checking if the path is found locally\n",
    "if not os.path.exists(RES_PATH):\n",
    "    print( 'cannot find mesh resources dir, please update RES_PATH')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('found resources')\n",
    "\n",
    "# Loading libraries for basic geometry processing\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 6  # (M) There are 6 views in the example (V1 to V6)\n",
    "num_correspondences = 12  # (P) There are 12 correspondence sets (S1 to S12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 shape of Vertices: (40256, 3)\n",
      "M2 shape of Vertices: (30373, 3)\n",
      "M3 shape of Vertices: (40247, 3)\n",
      "M4 shape of Vertices: (31697, 3)\n",
      "M5 shape of Vertices: (38297, 3)\n",
      "M6 shape of Vertices: (37737, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load multi-views point cloud models M1 ~ M6\n",
    "mesh_fp1 = os.path.join(RES_PATH,'bun000.ply')\n",
    "assert os.path.exists(mesh_fp1), 'Cannot find:' + mesh_fp1\n",
    "M1 = trimesh.load(mesh_fp1)\n",
    "print('M1 shape of Vertices:', M1.vertices.shape)\n",
    "\n",
    "mesh_fp2 = os.path.join(RES_PATH,'bun090.ply')\n",
    "assert os.path.exists(mesh_fp2), 'Cannot find:' + mesh_fp2\n",
    "M2 = trimesh.load(mesh_fp2)\n",
    "print('M2 shape of Vertices:', M2.vertices.shape)\n",
    "\n",
    "mesh_fp3 = os.path.join(RES_PATH,'bun180.ply')\n",
    "assert os.path.exists(mesh_fp3), 'Cannot find:' + mesh_fp3\n",
    "M3 = trimesh.load(mesh_fp3)\n",
    "print('M3 shape of Vertices:', M3.vertices.shape)\n",
    "\n",
    "mesh_fp4 = os.path.join(RES_PATH,'bun270.ply')\n",
    "assert os.path.exists(mesh_fp4), 'Cannot find:' + mesh_fp4\n",
    "M4 = trimesh.load(mesh_fp4)\n",
    "print('M4 shape of Vertices:', M4.vertices.shape)\n",
    "\n",
    "mesh_fp5 = os.path.join(RES_PATH,'top2.ply')\n",
    "assert os.path.exists(mesh_fp5), 'Cannot find:' + mesh_fp5\n",
    "M5 = trimesh.load(mesh_fp5)\n",
    "print('M5 shape of Vertices:', M5.vertices.shape)\n",
    "\n",
    "mesh_fp6 = os.path.join(RES_PATH,'chin.ply')\n",
    "assert os.path.exists(mesh_fp6), 'Cannot find:' + mesh_fp6\n",
    "M6 = trimesh.load(mesh_fp6)\n",
    "print('M6 shape of Vertices:', M6.vertices.shape)\n",
    "\n",
    "# Create a list to store models to be registered\n",
    "models = [M1.vertices.copy(), M2.vertices.copy(), M3.vertices.copy(), M4.vertices.copy(), M5.vertices.copy(), M6.vertices.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "import trimesh\n",
    "import os\n",
    "\n",
    "def compute_threshold(distances):\n",
    "    # Calculate the 75th and 25th percentiles of the distances\n",
    "    q75, q25 = np.percentile(distances, [75 ,25])\n",
    "    iqr = q75 - q25  # Interquartile range\n",
    "    return q75 + 1.5 * iqr  # Calculate the threshold using IQR\n",
    "\n",
    "def find_nearest_pts(source_pts, target_pts, threshold, filter=True):\n",
    "    # Build a KDTree for each point cloud\n",
    "    kdtree_src = KDTree(source_pts)    \n",
    "    # Query the tree for nearest points to each point in the other point cloud\n",
    "    d_src, id_src = kdtree_src.query(target_pts, return_distance=True)     \n",
    "    # Gather nearest points based on the indices returned by KDTree\n",
    "    nearest_src = np.squeeze(source_pts[id_src])\n",
    "\n",
    "    kdtree_target = KDTree(target_pts)\n",
    "    d_target, id_target = kdtree_target.query(nearest_src, return_distance=True)\n",
    "    nearest_target = np.squeeze(target_pts[id_target])\n",
    "\n",
    "    \n",
    "    if filter == True:\n",
    "        valid_id = d_src.flatten() < threshold        \n",
    "        nearest_src = nearest_src[valid_id]\n",
    "        nearest_target = nearest_target[valid_id]\n",
    "                    \n",
    "    return nearest_src, nearest_target\n",
    "\n",
    "def process_selected_dataset_pairs(point_sets, pairs_to_process, save_pairs=True, filter=True):\n",
    "    # Ensure the specified directory exists; if not, create it\n",
    "    # if not os.path.exists(folder_path):\n",
    "    #     os.makedirs(folder_path)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for (i, j) in pairs_to_process:\n",
    "        \n",
    "        # Create KDTree for the j-th point set\n",
    "        tree = KDTree(point_sets[j]) #source pts\n",
    "        # Find distances to all points in the i-th point set\n",
    "        distances, _ = tree.query(point_sets[i], return_distance=True) #target pts\n",
    "        # Compute threshold based on distances\n",
    "        threshold = compute_threshold(distances)\n",
    "        #threshold = 0.02\n",
    "        \n",
    "        # Find nearest points using the threshold\n",
    "        nearest_pts, dest_pts = find_nearest_pts(point_sets[j], point_sets[i], threshold, filter=True)\n",
    "        Y.append(nearest_pts)\n",
    "        X.append(dest_pts)\n",
    "\n",
    "        if save_pairs == True:\n",
    "            folder_path = './correspondences'  # Define the path of the folder to save the files\n",
    "            #Export the nearest points and corresponding points to PLY files in the specified folder\n",
    "            mesh1 = trimesh.Trimesh(vertices=nearest_pts)\n",
    "            mesh1.export(os.path.join(folder_path, f'nearest_points_from_{j}_to_{i}.ply'))\n",
    "            mesh2 = trimesh.Trimesh(vertices=dest_pts)\n",
    "            mesh2.export(os.path.join(folder_path, f'corresponding_points_from_{i}_to_{j}.ply'))\n",
    "        \n",
    "        # #Check\n",
    "        # print(nearest_pts.shape)\n",
    "        # print(dest_pts.shape)        \n",
    "                \n",
    "    return X, Y\n",
    "\n",
    "pairs_to_process = [(0, 1), (1, 2), (2, 3), (3, 0), (0, 4), (1, 4), (2, 4), (3, 4),(0, 5), (1, 5), (2, 5), (3, 5)]\n",
    "\n",
    "X, Y = process_selected_dataset_pairs(models, pairs_to_process, save_pairs=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate normals to assign weights for correspondeces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstsq_plane_fitting(surface_points, k):\n",
    "    ### fill in this function. normals should have same dimension as surface_points (nx3)\n",
    "    ### k is the number of neighbours\n",
    "\n",
    "    num_points, _ = surface_points.shape\n",
    "    # Construct KDTree based on point samples\n",
    "    tree = KDTree(surface_points)\n",
    "    # Get k-neighbours' indices of each point (include itself)\n",
    "    _, indices = tree.query(surface_points, k)\n",
    "    # Initialise normals\n",
    "    normals = np.zeros([num_points, 3])\n",
    "    for point in range(num_points):\n",
    "        neighbours = surface_points[indices[point], :]\n",
    "        (a, b, c), residual, rank, s = np.linalg.lstsq(neighbours, np.ones([k]), rcond=-1)\n",
    "        normal = (a, b, c)\n",
    "        nn = np.linalg.norm(normal)\n",
    "        normal /= nn\n",
    "        normals[point, :] = normal\n",
    "    \n",
    "    return normals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the View–Correspondence Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the View–Correspondence Mapping Table, construct the Cα and Cβ matrices.\n",
    "# These are \"view selection matrices\" that map correspondence sets to their respective views.\n",
    "\n",
    "# Define the mappings as provided in the table\n",
    "alpha_mapping = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]\n",
    "beta_mapping = [2, 3, 4, 1, 5, 5, 5, 5, 6, 6, 6, 6]\n",
    "\n",
    "# Initialize the selection matrices with zeros\n",
    "C_alpha = np.zeros((3 * num_views, 3 * num_correspondences))\n",
    "C_beta = np.zeros((3 * num_views, 3 * num_correspondences))\n",
    "\n",
    "# Fill in the selection matrices based on the mappings\n",
    "for mu in range(num_correspondences):\n",
    "    view_alpha = alpha_mapping[mu] - 1  # Adjust for zero-based indexing\n",
    "    view_beta = beta_mapping[mu] - 1  # Adjust for zero-based indexing\n",
    "\n",
    "    # Each correspondence set affects 3 rows and 3 columns, for x, y, z components\n",
    "    C_alpha[3*view_alpha:3*(view_alpha+1), 3*mu:3*(mu+1)] = np.eye(3)\n",
    "    C_beta[3*view_beta:3*(view_beta+1), 3*mu:3*(mu+1)] = np.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Q Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q(X, Y):\n",
    "    # method1: Weights all initialized to 1 for now\n",
    "    # weights = [np.ones(len(X[mu])) for mu in range(num_correspondences)]\n",
    "    \n",
    "    # method2: Compute weights based on the normals between the point pair\n",
    "    weights = []\n",
    "    for i in range(num_correspondences):\n",
    "        normals_X = lstsq_plane_fitting(X[i], 3)\n",
    "        normals_Y = lstsq_plane_fitting(Y[i], 3)\n",
    "        weight = np.einsum('ij,ij->i', normals_X, normals_Y)\n",
    "        weights.append(weight)\n",
    "        \n",
    "    ## Compute Q_R\n",
    "    # Initialize the H matrices as zero matrices of the appropriate size\n",
    "    Hxx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hyy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hxy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Hyx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "\n",
    "    # Calculate the H matrices\n",
    "    for mu in range(num_correspondences):\n",
    "        # Weight each point's contribution to the outer product\n",
    "        weighted_X = X[mu] * weights[mu][:, np.newaxis]\n",
    "        weighted_Y = Y[mu] * weights[mu][:, np.newaxis]\n",
    "\n",
    "        Hxx_mu = weighted_X.T @ X[mu]\n",
    "        Hyy_mu = weighted_Y.T @ Y[mu]\n",
    "        Hxy_mu = weighted_X.T @ Y[mu]\n",
    "        Hyx_mu = Hxy_mu.T  # Hyx is the transpose of Hxy\n",
    "\n",
    "        # Place the computed matrices in their appropriate blocks in the H matrices\n",
    "        Hxx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hxx_mu\n",
    "        Hyy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hyy_mu\n",
    "        Hxy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hxy_mu\n",
    "        Hyx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = Hyx_mu\n",
    "\n",
    "    # Using the computed matrices to calculate Q_R\n",
    "    Q_R = C_alpha @ Hxx @ C_alpha.T + C_beta @ Hyy @ C_beta.T - C_alpha @ Hxy @ C_beta.T - C_beta @ Hyx @ C_alpha.T\n",
    "\n",
    "    ## Compute Q_R_T\n",
    "    # Step 1: Compute W_mu as the sum of weights for each correspondence\n",
    "    W_mu = np.array([np.sum(weights[mu]) for mu in range(num_correspondences)])\n",
    "\n",
    "    # Step 2: Create the W matrix\n",
    "    W = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    for mu in range(num_correspondences):\n",
    "        W[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.eye(3) * W_mu[mu]\n",
    "\n",
    "    # Step 3: Compute the matrix Gamma\n",
    "    N = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    for mu in range(num_correspondences):\n",
    "        N[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.eye(3) * len(X[mu])\n",
    "\n",
    "    Gamma_matrix = W @ (C_alpha - C_beta).T @ np.linalg.pinv((C_alpha - C_beta) @ N @ (C_alpha - C_beta).T) @ (C_alpha - C_beta) @ W\n",
    "    # Extract gamma_coefficients from Gamma's diagonal blocks\n",
    "    gamma_coefficients = np.array([Gamma_matrix[3*mu, 3*mu] for mu in range(num_correspondences)])\n",
    "\n",
    "    # Step 4: Compute the weighted centroids for each correspondence set\n",
    "    weighted_centroids_x = [np.average(X[mu], weights=weights[mu], axis=0) for mu in range(num_correspondences)]\n",
    "    weighted_centroids_y = [np.average(Y[mu], weights=weights[mu], axis=0) for mu in range(num_correspondences)]\n",
    "\n",
    "    # Step 5: Compute the G matrices\n",
    "    Gxx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gyy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gxy = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "    Gyx = np.zeros((3 * num_correspondences, 3 * num_correspondences))\n",
    "\n",
    "    for mu in range(num_correspondences):\n",
    "        Gxx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_x[mu], weighted_centroids_x[mu]) * gamma_coefficients[mu]\n",
    "        Gyy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_y[mu], weighted_centroids_y[mu]) * gamma_coefficients[mu]\n",
    "        Gxy[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_x[mu], weighted_centroids_y[mu]) * gamma_coefficients[mu]\n",
    "        Gyx[3*mu:3*(mu+1), 3*mu:3*(mu+1)] = np.outer(weighted_centroids_y[mu], weighted_centroids_x[mu]) * gamma_coefficients[mu]\n",
    "\n",
    "    # Now use the G matrices and the view selection matrices to compute Q_R_T\n",
    "    Q_R_T = -C_alpha @ Gxx @ C_alpha.T + C_alpha @ Gxy @ C_beta.T + C_beta @ Gyx @ C_alpha.T - C_beta @ Gyy @ C_beta.T\n",
    "\n",
    "    # Compute Q matrix\n",
    "    Q = Q_R + Q_R_T\n",
    "\n",
    "    return Q, weighted_centroids_x, weighted_centroids_y, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative algorithm to solve for R and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_and_T(R, T, Q, weighted_centroids_x, weighted_centroids_y, W):\n",
    "    ## Solve for R\n",
    "    # Iterate over each view to optimize its rotation matrix\n",
    "    for j in range(num_views):\n",
    "        # Partition R into R_L, R_j, and R_U\n",
    "        R_L = R[:, :3*j]\n",
    "        R_j = R[:, 3*j:3*(j+1)]\n",
    "        R_U = R[:, 3*(j+1):]\n",
    "\n",
    "        # Partition Q into corresponding blocks\n",
    "        Q_jL = Q[3*j:3*(j+1), :3*j]\n",
    "        Q_jU = Q[3*j:3*(j+1), 3*(j+1):]\n",
    "\n",
    "        # Construct the S_j matrix for the j-th rotation\n",
    "        S_j = Q_jL @ R_L.T + Q_jU @ R_U.T\n",
    "\n",
    "        # Perform SVD of -S_j\n",
    "        U, _, Vt = np.linalg.svd(-S_j)\n",
    "\n",
    "        # Calculate the optimal R_j and update the corresponding block in R\n",
    "        R[:, 3*j:3*(j+1)] = Vt.T @ np.diag([1, 1, np.linalg.det(Vt.T @ U.T)]) @ U.T\n",
    "\n",
    "    ## Solve for T\n",
    "    # Initialize Z as an empty list to collect the blocks\n",
    "    Z_blocks = []\n",
    "\n",
    "    # Construct Z by concatenating the relative displacements of the rotated centroids\n",
    "    for mu in range(num_correspondences):\n",
    "        rotated_centroid_x = R @ C_alpha[:, 3*mu:3*(mu+1)] @ weighted_centroids_x[mu]\n",
    "        rotated_centroid_y = R @ C_beta[:, 3*mu:3*(mu+1)] @ weighted_centroids_y[mu]\n",
    "        Z_block = rotated_centroid_x - rotated_centroid_y\n",
    "        Z_blocks.append(Z_block)\n",
    "\n",
    "    Z = np.concatenate(Z_blocks, axis=0)  # Combine the blocks vertically\n",
    "\n",
    "    # Construct matrices A and B\n",
    "    A = (C_alpha - C_beta) @ W @ (C_alpha - C_beta).T\n",
    "    B = (C_alpha - C_beta) @ W @ Z\n",
    "\n",
    "    # Solve for T_min using the pseudo-inverse of A\n",
    "    T_min = -np.linalg.pinv(A) @ B\n",
    "\n",
    "    T = T_min.reshape((3*num_views, 1))\n",
    "\n",
    "    return R, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simultaneous registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simultaneous_multiscans_registration(scans, X, Y, max_iterations=30, tolerance=1e-6):\n",
    "    R = np.hstack([np.eye(3)] * num_views)\n",
    "    T = np.zeros((3*num_views, 1))\n",
    "\n",
    "    for iteration in range(1, max_iterations+1):\n",
    "        Q, weighted_centroids_x, weighted_centroids_y, W = compute_Q(X, Y)\n",
    "        R, T = compute_R_and_T(R, T, Q, weighted_centroids_x, weighted_centroids_y, W)\n",
    "\n",
    "        # Update each model\n",
    "        for j in range(num_views):\n",
    "            # Extract the rotation matrix R_j for view j\n",
    "            R_j = R[:, 3*j:3*(j+1)]\n",
    "            \n",
    "            # Extract the translation vector T_j for view j\n",
    "            T_j = T[3*j:3*(j+1)]\n",
    "\n",
    "            scans[j] = (R_j @ models[j].T + T_j).T\n",
    "        X, Y = process_selected_dataset_pairs(scans, pairs_to_process, save_pairs=False, filter=False)\n",
    "\n",
    "        if iteration == max_iterations:\n",
    "            print(iteration, 'maximum iteration reached.')\n",
    "\n",
    "    return scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 maximum iteration reached.\n"
     ]
    }
   ],
   "source": [
    "models = simultaneous_multiscans_registration(models, X, Y)\n",
    "\n",
    "for i, model_vertices in enumerate(models):\n",
    "    directory = './results/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"registered_M{i+1}.ply\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    model = trimesh.points.PointCloud(model_vertices)\n",
    "    model.export(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
